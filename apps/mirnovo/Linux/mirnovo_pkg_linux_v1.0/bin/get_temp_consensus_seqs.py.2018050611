
# !/usr/bin/env python

from __future__ import division
from sys import argv
from sys import exit
import os.path
import subprocess
import gzip
import re
import Queue
import threading
import time
import csv
import os
import sys


def cluster_parser(fasta_file):
    """Parses a cluster alignmnet outp from usearch, stores the
       seqs in a matrix like [['A', 'T', 'C', ..]],
    """
    fasta = open(fasta_file)

    cluster_label_list = []
    cluster_seq_matrix = []
    for line in fasta:
        line = line.rstrip()
        if line.startswith('>'):
            cluster_label_list += [line[1:]]
        else:
            cluster_seq_matrix += [list(line)]
	    tt = list(line)
	    #print(tt)

    fasta.close()
    return cluster_label_list, cluster_seq_matrix


def calc_seq_position_stats(cluster_label_list, cluster_seq_matrix):
    """Calculates position statistics for a cluster
       and stores them in posit_diction
    """
#    print(cluster_label_list)
#    print(cluster_seq_matrix)

    read_variant_depths = []
    for v in cluster_label_list:
        depth = int(v.split("_x")[1])
        #depth = int(depth.replace('x', ''))
        read_variant_depths.append(depth)
        #print(depth)

    variants_total_depth = sum(read_variant_depths)
    #print(read_variant_depths)
    #print(variants_total_depth)

    seq_number = len(cluster_seq_matrix)
    seq_len = len(cluster_seq_matrix[0])

    # initialise posit_diction
    posit_diction = {}
    for i in range(seq_len):
        pos = 'pos' + str(i)
        posit_diction[pos] = []
        # will be like {'pos14': [], 'pos15': [],..}
        # value of each key will be of form [%As, %Ts, %Cs, %Gs, %Ns, %gaps]
        # where %As: perc. of seqs with A at this position (see diction_key)
    # transpose cluster_seq_matrix and count how many elems of eg matr[0] are 'A'
    T_clust_seq_matr = zip(*cluster_seq_matrix)

    #print(T_clust_seq_matr)


    for i in range(len(T_clust_seq_matr)):
        T_clust_seq_matr[i] = list(T_clust_seq_matr[i])
    # now matrix is transposed
    # each elem's index corresponds to seq-position ->
    # T_clust_seq_matr[i]: i-th position of cluster alignment

    for i in range(len(T_clust_seq_matr)):
        pos = 'pos' + str(i)

        tmp_dict = {'A': 0, 'T': 0, 'G': 0, 'C': 0, 'N': 0, '-': 0}
        #print(T_clust_seq_matr[i])

        for j, nt in enumerate(T_clust_seq_matr[i]):
	    nt = nt.upper()
            tmp_dict[nt] += read_variant_depths[j]

        for x in tmp_dict:
            tmp_dict[x] /= variants_total_depth
            tmp_dict[x] = round(tmp_dict[x], 5)
        #print(tmp_dict)

        tmp_list = []
        for k in ('A', 'T', 'C', 'G', 'N', '-'):
            #print(tmp_dict[k])
            tmp_list.append(tmp_dict[k])
            posit_diction[pos] = tmp_list

        tmp_ratios_sum = round(sum(tmp_list), 2)

        # validate that ratios are consistent
        if tmp_ratios_sum != 1.0:
            print("Error! As+Ts+Cs+Gs+Ns+gaps do not sum up to 1.0! Exiting... (Index: %s)") % (i)
            print(tmp_ratios_sum)
            print(type(tmp_ratios_sum))
            print(type(1.0))
            print([As, Ts, Cs, Gs, Ns, gaps])
            exit(0)


    return posit_diction

def CALCUL_posit_stats(posit_diction):
    """Calculates pos_list & T_pos_list (seq_stats table) for a single
       cluster of seqs, to process on seq-stats more easily
    """
    # keys of posit_diction not sorted
    # sort them and store them in list
    pos_list = []
    for i in range(len(posit_diction)):
        pos = 'pos' +str(i)
        pos_list += [posit_diction[pos]]

    T_pos_list = zip(*pos_list) # is a list of tuples
    # each tuple -> a seq  ## tuple elements -> alignm-positions
    #for line in T_pos_list:
        #print line
    #print "POS_LIST"
    #for line in pos_list:
        #print line
    # return pos_list matrix & its transposed version (T_pos_list)
    return pos_list, T_pos_list

def find_consensus_complem_seq(pos_list):
    """Finds the consensus seq of a single cluster
    """
    base_list = ['A', 'T', 'C', 'G', 'N', '-']
    # find "dominant" nt at each position
    # dominant nt-> the nt at that position of the alignment
    #     with the highest percentage


    dominant_nts = []
    for pos in range(len(pos_list)):
        # find the index of pos_list[pos] with the dom_nt
        dom_nt_index = [i for i, j in enumerate(pos_list[pos]) if j == max(pos_list[pos])]
        # returns a list with one elem; in case of >1 dominant nts -> more elems in list
        index = dom_nt_index[0] # dom_nt_index is already a list
    	dominant_nts += [base_list[index]]
	""" deprecated:
	if len(dom_nt_index) == 1:
            index = dom_nt_index[0] # dom_nt_index is already a list
            dominant_nts += [base_list[index]]
            rev_complement_dominant_nts += [rev_compl_base_list[index]]
        elif len(dom_nt_index) > 1:
            # for cases of >1 dominant nts, occuring at equal percentages in cluster
            index = dom_nt_index[0] # pick first dominant nt (randomly)
            dominant_nts += [base_list[index].lower()]
            rev_complement_dominant_nts += [rev_compl_base_list[index].lower()]
	"""
    # expect a list ['A', 'T', 'A',.... ] of len = len(pos_list)
    # this list is the consensus seq
    cons_seq_pre = ''.join([base for base in dominant_nts])
    # trail gaps and N's from the end from the ends of cons_seq
    cons_seq = cons_seq_pre.strip('-')
    cons_seq = cons_seq.replace('-', '')
    cons_sequence = cons_seq.strip('N')

    return cons_sequence





# **** multi-threading module ****
exitFlag = 0
writeConsSeqsLock = threading.Lock()
updateDictLock = threading.Lock()


class clusterFeaturesThread (threading.Thread):
    def __init__(self, threadID, q):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.q = q
    def run(self):
        #print "Starting " + self.name
        getFeaturesForCluster(self.threadID, self.q)
        #print "Exiting " + self.name



def getFeaturesForCluster(threadID, q):
    #print("threadID: "+ str(threadID))

    while not exitFlag:
        queueLock.acquire()
        if not workQueue.empty():
            #data_index = q.get()
            #cluster_file_name = clu_list[data_index]
            cluster_file_name = q.get()
            queueLock.release()

            cluster_file = '%s/%s' % (usearch_dir, cluster_file_name)
            #print("%s processing cluster_file: %s" % (threadID, cluster_file))

            # parse cluster_file - get seqs
            cluster_label_list, cluster_seq_matrix = cluster_parser(cluster_file)

            # calc. nucleotide stats at each alignm. position - store in diction
            posit_diction = calc_seq_position_stats(cluster_label_list, cluster_seq_matrix)

            # store pos_stats in pos_list and T_pos_list
            pos_list, T_pos_list = CALCUL_posit_stats(posit_diction)

            #store cluster number ## to use for writing cons_seqs_file & feature_table
            #print(cluster_file_name)
            cluster_number = cluster_file_name.split('.')[1]
            #print("cluster_number: "+ cluster_number)

            # find consensus sequence & rev. compl. and append to cons_seqs & rev_compl_cons file
            cons_sequence = find_consensus_complem_seq(pos_list)

            #print(cons_sequence)
            #print(" cl_" + cluster_number)


            writeConsSeqsLock.acquire()
            cons_seqs_file.write('>cons_seqs_cluster.%s\n' % cluster_number)
            cons_seqs_file.write(cons_sequence + '\n')
            writeConsSeqsLock.release()

        else:
            queueLock.release()
        time.sleep(1)





if __name__=='__main__':

    usearch_dir = argv[1]
    cur_out_dir = argv[2]
    job_id = argv[3]
    NUM_OF_THREADS = 40      # add as extra argument later on

    #put the filenames of all cluster files in a list
    cmd = 'ls -v %s| grep "alignm\.[0-9]*$" | paste -sd " " -' % (usearch_dir)
    #print(cmd)
    clu_list = subprocess.check_output(cmd, shell = True).rstrip().split(' ')
    #print(clu_list)


    # get tmp consensus sequence for each cluster using multiple threads
    queueLock = threading.Lock()
    workQueue = Queue.Queue(len(clu_list))
    threads = []


    print("["+job_id+"]>> Assessing tmp-consensus sequence for each cluster...(non-refined stage)")
    # files to be written by multiple threads, open/close once
    cons_seqs_file = open(cur_out_dir+"/consensus_sequences.fa", "w")
    for threadID in range(0, NUM_OF_THREADS):
        #print("threadID: "+str(threadID))
        thread = clusterFeaturesThread(threadID, workQueue)
        thread.start()
        threads.append(thread)

    # Fill the queue
    queueLock.acquire()
    for cluster_file_name in clu_list:
        workQueue.put(cluster_file_name)
    queueLock.release()

    # Wait for queue to empty
    while not workQueue.empty():
        pass

    # Notify threads it's time to exit
    exitFlag = 1

    # Wait for all threads to complete
    for t in threads:
        t.join()

    print("["+job_id+"]<< Assessment of tmp-consensus sequences complete!\n")

    cons_seqs_file.close()


